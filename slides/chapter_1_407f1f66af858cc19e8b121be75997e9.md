---
title: Insert title here
key: 407f1f66af858cc19e8b121be75997e9

---
## Fit Logistic Regression

```yaml
type: "TitleSlide"
key: "6daa5ec860"
```

`@lower_third`

name: Sundar Krishnan
title: Lead Data Scientist


`@script`
In the previous lecture, we went through the concept of logistic regression and how it can be used to predict binary outcomes. In this lecture, we will understand how to write a python code to train a logistic regression model.


---
## Data

```yaml
type: "FullCodeSlide"
key: "d595d3eee5"
```

`@part1`
The data for this exercise is taken from the [UCI Machine learning repository](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing).

**Load Data**
```
import pandas as pd
df = pd.read_excel("bank.xlsx")
```
**Sneak peek of the data**
```
df.head()
```
![df.head](https://github.com/Sundar0989/datacamp/blob/master/Data%20-%20Sneak%20Peek.png)


`@script`



---
## Information about the data

```yaml
type: "FullCodeSlide"
key: "044e6d48e9"
```

`@part1`
- 7 Continuous input variables (int64)
- 9 Categorical input variables (object)
- 1 target variable  - **'y'** (object)

```
df.info
```
![df.info](https://github.com/Sundar0989/datacamp/blob/master/Data%20-%20Information.png)


`@script`



---
## What we need to predict?

```yaml
type: "FullCodeSlide"
key: "700714b05b"
```

`@part1`
**Predict** - Whether the client subscribed for a term deposit (yes/no)?
```
df['target'] = df['y'].apply(lambda x: 1 if x == 'yes' else 0)
```
**Count of each levels**
```
df.target.value_counts()
```
**Drop the categorical target column**
```
df.drop('y',axis=1,inplace=True)
```


`@script`



---
## Packages to fit logistic regression

```yaml
type: "FullSlide"
key: "c3ab27aa49"
```

`@part1`
1. Statsmodels
2. Sklearn (Widely used)

**Note:** The input data should be **continuous**.


`@script`
In python, we can use two packages to train a logistic regression model. The first one is statsmodels package and second one is widely used sklearn package. The input variables to both the packages will accept only continuous variable. Then, what should we do to incorporate categorical variables in the fi


---
## Train/Test split (Honest Assessment)

```yaml
type: "FullCodeSlide"
key: "e1e204df6d"
```

`@part1`
```
from sklearn.model_selection import train_test_split

X = df[['age','balance','day','duration','campaign','pdays','previous']]
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, 
random_state=42)
```

The train and test dataset has 3,029 and 1,492 observations respectively. 
```
len(X_train)
len(X_test)
```


`@script`



---
## Statsmodel fit

```yaml
type: "FullCodeSlide"
key: "c3fa5f548a"
```

`@part1`
```
import statsmodels.api as sm

logit = sm.Logit(y_train, X_train).fit()
logit.summary()
```
![statsmodel](https://github.com/Sundar0989/datacamp/blob/master/Statsmodels%20Logit%20fit.png)


`@script`



---
## Sklearn fit

```yaml
type: "FullCodeSlide"
key: "57bc1a5edb"
```

`@part1`
```
from sklearn.linear_model import LogisticRegression
clf = LogisticRegression()

clf.fit(X_train,y_train)
```

```
import numpy as np
pd.DataFrame(np.transpose(clf.coef_),index=X_train.columns,columns=['coef'])
```
![sklearn](https://github.com/Sundar0989/datacamp/blob/master/Sklearn%20logit%20fit.png)


`@script`



---
## Comparison of Fit outputs

```yaml
type: "TwoColumns"
key: "6c03b8f7d0"
```

`@part1`
**Statsmodel Coef**

![statsmodel](https://github.com/Sundar0989/datacamp/blob/master/Statsmodel%20logit%20coef.png)


`@part2`
**Sklearn Coef**

![sklearn](https://github.com/Sundar0989/datacamp/blob/master/Sklearn%20logit%20fit.png)


`@script`



---
## Why the fit coefficients are different?

```yaml
type: "FullSlide"
key: "3b3cf8593a"
```

`@part1`
By default, _sklearn_ fits an intercept which _statsmodel_ package does not. In addition, sklearn uses regularization by default.

![fit_intercept](https://github.com/Sundar0989/datacamp/blob/master/sklearn%20fit%20intercept.png)

To bring consistency, one of these options will work

1. Set **fit_intercept=False** in sklearn model (This is not recommended)
2. Add a **constant** in the X_train dataset before fitting statsmodel
3. Using a large C value or changing the regularization method or try both


`@script`



---
## Sklearn model without fit intercept

```yaml
type: "TwoColumns"
key: "a05fc5b150"
```

`@part1`
**Statsmodel fit**
```
import statsmodels.api as sm

logit = sm.Logit(y_train, X_train).fit()
logit.summary()
```
![statsmodel](https://github.com/Sundar0989/datacamp/blob/master/Statsmodel%20logit%20coef.png)


`@part2`
**sklearn fit without intercept**
```
from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(fit_intercept=False)

clf.fit(X_train,y_train)
```


`@script`



---
## Updated statsmodel fit

```yaml
type: "FullCodeSlide"
key: "464ab6a7b5"
```

`@part1`



`@script`



---
## Final Slide

```yaml
type: "FinalSlide"
key: "cbd484c536"
```

`@script`


